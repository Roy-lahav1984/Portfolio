{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df6257a8",
   "metadata": {},
   "source": [
    "\n",
    "# Stroke Prediction — Data Cleaning & Preparation\n",
    "\n",
    "**Author:** _Your Name_  \n",
    "**Dataset:** Stroke Prediction Dataset (`data/stroke.csv`)\n",
    "\n",
    "## Objective\n",
    "Prepare and clean the Stroke Prediction dataset for machine learning analysis.  \n",
    "We'll handle missing values, encode categorical features, and scale numerical variables to produce a reliable dataset for EDA and modeling.\n",
    "\n",
    "## Steps\n",
    "1. Load and inspect data  \n",
    "2. Handle missing values  \n",
    "3. Encode categorical features  \n",
    "4. Scale numeric columns  \n",
    "5. Export cleaned dataset\n",
    "\n",
    "## Tools\n",
    "- Python: `pandas`, `numpy`, `matplotlib`\n",
    "- Scikit-learn: `StandardScaler`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbf0df6",
   "metadata": {},
   "source": [
    "## 1) Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c3ef4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 140)\n",
    "\n",
    "DATA_PATH = 'data/stroke.csv'\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    raise FileNotFoundError(f\"Dataset not found at {DATA_PATH}. Please add it to the data/ folder.\")\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print('Raw dataset shape:', df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50721eb7",
   "metadata": {},
   "source": [
    "## 2) Basic Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73da381a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.info()\n",
    "df.describe(include='all').T.head(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584cdaa3",
   "metadata": {},
   "source": [
    "## 3) Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68addf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fill BMI with median\n",
    "if 'bmi' in df.columns:\n",
    "    df['bmi'].fillna(df['bmi'].median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c63c3d8",
   "metadata": {},
   "source": [
    "## 4) Clean and Normalize Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8096ddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cat_cols = df.select_dtypes('object').columns\n",
    "for c in cat_cols:\n",
    "    df[c] = df[c].str.strip().str.lower()\n",
    "\n",
    "for c in cat_cols:\n",
    "    print(f\"{c}: {df[c].unique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d681236",
   "metadata": {},
   "source": [
    "## 5) Outlier Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32be37c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numeric_cols = ['age', 'avg_glucose_level', 'bmi']\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns:\n",
    "        plt.figure(figsize=(6,3))\n",
    "        plt.boxplot(df[col], vert=False)\n",
    "        plt.title(f'{col} Distribution')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5933647",
   "metadata": {},
   "source": [
    "## 6) Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dbd609",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manual binary encodings\n",
    "binary_map = {\n",
    "    'gender': {'male': 1, 'female': 0},\n",
    "    'ever_married': {'yes': 1, 'no': 0},\n",
    "    'residence_type': {'urban': 1, 'rural': 0}\n",
    "}\n",
    "for col, mapping in binary_map.items():\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].map(mapping)\n",
    "\n",
    "# One-hot encoding for multi-category variables\n",
    "multi_cat = [c for c in df.select_dtypes('object').columns if c not in binary_map]\n",
    "df = pd.get_dummies(df, columns=multi_cat, drop_first=True)\n",
    "print('After encoding shape:', df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fb230f",
   "metadata": {},
   "source": [
    "## 7) Scale Numerical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a73b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scale_cols = ['age','avg_glucose_level','bmi']\n",
    "for col in scale_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = scaler.fit_transform(df[[col]])\n",
    "\n",
    "df[scale_cols].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b49dd4f",
   "metadata": {},
   "source": [
    "## 8) Target Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cb1ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'stroke' in df.columns:\n",
    "    stroke_counts = df['stroke'].value_counts(normalize=True) * 100\n",
    "    stroke_counts.plot(kind='bar', color=['lightblue', 'salmon'])\n",
    "    plt.title('Stroke Class Distribution (%)')\n",
    "    plt.xlabel('Stroke (0=No, 1=Yes)')\n",
    "    plt.ylabel('Percentage')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print('Class distribution (%):\\n', stroke_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3abc7d",
   "metadata": {},
   "source": [
    "## 9) Export Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06662f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OUT_DIR = 'data_cleaned'\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "out_path = os.path.join(OUT_DIR, 'stroke_cleaned.csv')\n",
    "df.to_csv(out_path, index=False)\n",
    "print('Cleaned dataset saved to:', out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a029043b",
   "metadata": {},
   "source": [
    "\n",
    "## Appendix\n",
    "- `bmi` filled with median  \n",
    "- Binary and one-hot encodings applied  \n",
    "- Numeric features scaled for model readiness  \n",
    "- Target imbalance noted for modeling adjustments (e.g., SMOTE or class weighting)\n",
    "\n",
    "Next: **02_stroke_eda.ipynb** — exploratory data analysis & feature relationships\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
